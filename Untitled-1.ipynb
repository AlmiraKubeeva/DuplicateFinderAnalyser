{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "def convertPDFToTxt(pdfFilePath):\n",
    "        \n",
    "        with open(pdfFilePath, 'rb') as pdf_file:\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            text = \"\"\n",
    "            # Чтение содержимого каждой страницы PDF и объединение в одну строку\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(pdfFilePath):\n",
    "    with open(pdfFilePath, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        images = []\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            if '/XObject' in page['/Resources']:\n",
    "                xObject = page['/Resources']['/XObject'].get_object()\n",
    "                for obj in xObject:\n",
    "                    if xObject[obj]['/Subtype'] == '/Image':\n",
    "                        images.append(xObject[obj].getData())\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeprecationError",
     "evalue": "getData is deprecated and was removed in PyPDF2 3.0.0. Use get_data instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDeprecationError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mextract_images_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mfrima\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDownloads\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mPDFAndPic.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mextract_images_from_pdf\u001b[1;34m(pdfFilePath)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m xObject:\n\u001b[0;32m     10\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m xObject[obj][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Subtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Image\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m                 images\u001b[38;5;241m.\u001b[39mappend(\u001b[43mxObject\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images\n",
      "File \u001b[1;32mc:\\Users\\frima\\miniconda3\\lib\\site-packages\\PyPDF2\\generic\\_data_structures.py:835\u001b[0m, in \u001b[0;36mEncodedStreamObject.getData\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetData\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m]:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m     \u001b[43mdeprecation_with_replacement\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgetData\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m3.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_data()\n",
      "File \u001b[1;32mc:\\Users\\frima\\miniconda3\\lib\\site-packages\\PyPDF2\\_utils.py:369\u001b[0m, in \u001b[0;36mdeprecation_with_replacement\u001b[1;34m(old_name, new_name, removed_in)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeprecation_with_replacement\u001b[39m(\n\u001b[0;32m    364\u001b[0m     old_name: \u001b[38;5;28mstr\u001b[39m, new_name: \u001b[38;5;28mstr\u001b[39m, removed_in: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    366\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    Raise an exception that a feature was already removed, but has a replacement.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     \u001b[43mdeprecation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEPR_MSG_HAPPENED\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremoved_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\frima\\miniconda3\\lib\\site-packages\\PyPDF2\\_utils.py:351\u001b[0m, in \u001b[0;36mdeprecation\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeprecation\u001b[39m(msg: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DeprecationError(msg)\n",
      "\u001b[1;31mDeprecationError\u001b[0m: getData is deprecated and was removed in PyPDF2 3.0.0. Use get_data instead."
     ]
    }
   ],
   "source": [
    "extract_images_from_pdf(\"C:\\\\Users\\\\frima\\\\Downloads\\\\PDFAndPic.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_content_from_pdf(pdfFilePath):\n",
    "    doc = fitz.open(pdfFilePath)\n",
    "    content = []\n",
    "  \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_content = {'texts': [], 'images': []}\n",
    "        \n",
    "        # Извлечение текста\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:\n",
    "            if b[\"type\"] == 0:  # block of text\n",
    "                page_content['texts'].append(b[\"lines\"])\n",
    "        \n",
    "        # Извлечение изображений\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            # Сохраняем изображение в списке вместе с его позицией на странице\n",
    "            page_content['images'].append({'position': img[1], 'bytes': image_bytes})\n",
    "        \n",
    "        content.append(page_content)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_content_from_pdf(pdfFilePath):\n",
    "    doc = fitz.open(pdfFilePath)\n",
    "    content = []\n",
    "  \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_content = {'texts': [], 'images': []}\n",
    "        \n",
    "        # Извлечение текста\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:\n",
    "            if b[\"type\"] == 0:  # block of text\n",
    "                page_content['texts'].append(b[\"lines\"])\n",
    "        \n",
    "        # Извлечение изображений\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            # Сохраняем изображение в списке вместе с его позицией на странице\n",
    "            page_content['images'].append({'position': img[1], 'bytes': image_bytes})\n",
    "        \n",
    "        content.append(page_content)\n",
    "  \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_content_from_pdf(pdfFilePath):\n",
    "    doc = fitz.open(pdfFilePath)\n",
    "    content = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_content = {'texts': [], 'images': []}\n",
    "        \n",
    "        # Извлечение текста\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:\n",
    "            if b[\"type\"] == 0:  # block of text\n",
    "                page_content['texts'].append(b[\"lines\"])\n",
    "        \n",
    "        # Извлечение изображений\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            \n",
    "            # Создаем байтовый поток из извлеченных байтов изображения\n",
    "            image_stream = io.BytesIO(image_bytes)\n",
    "            \n",
    "            # Открываем изображение с помощью Pillow\n",
    "            pillow_image = Image.open(image_stream)\n",
    "            # Сохраняем объект Pillow в списке вместе с его позицией на странице\n",
    "            page_content['images'].append({'position': img[1], 'image': pillow_image})\n",
    "        \n",
    "        content.append(page_content)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_content_from_pdf(pdfFilePath):\n",
    "    doc = fitz.open(pdfFilePath)\n",
    "    content = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_content = []\n",
    "        \n",
    "        # Извлечение блоков содержимого\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if block[\"type\"] == 0:  # block of text\n",
    "                for line in block[\"lines\"]:\n",
    "                    spans = []\n",
    "                    for span in line[\"spans\"]:\n",
    "                        spans.append(span[\"text\"])\n",
    "                    text = \" \".join(spans)\n",
    "                    page_content.append({\n",
    "                        \"type\": \"text\",\n",
    "                        \"content\": text,\n",
    "                        \"position\": block[\"bbox\"]  # bbox is the bounding box of the text block\n",
    "                    })\n",
    "            elif block[\"type\"] == 1:  # image block\n",
    "                xref = block[\"image\"]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                \n",
    "                # Создаем байтовый поток из извлеченных байтов изображения\n",
    "                image_stream = io.BytesIO(image_bytes)\n",
    "                \n",
    "                # Открываем изображение с помощью Pillow\n",
    "                pillow_image = Image.open(image_stream)\n",
    "                page_content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"content\": pillowimage,\n",
    "                    \"position\": block[\"bbox\"]  # bbox is the bounding box of the image block\n",
    "                })\n",
    "        \n",
    "        # Сортируем содержимое страницы по верхней границе bounding box (bbox[1]),\n",
    "        # чтобы сохранить вертикальный порядок следования элементов.\n",
    "        page_content.sort(key=lambda item: item[\"position\"][1])\n",
    "        content.extend(page_content)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_content_from_pdf(pdfFilePath):\n",
    "    doc = fitz.open(pdfFilePath)\n",
    "    content = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_content = []\n",
    "        \n",
    "        # Извлечение блоков содержимого и их сортировка по позиции\n",
    "        blocks = sorted(page.get_text(\"dict\", sort=True)[\"blocks\"], key=lambda b: b[\"bbox\"][1])\n",
    "        \n",
    "        for block in blocks:\n",
    "            if block[\"type\"] == 0:  # block of text\n",
    "                text = \"\"\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        text += span[\"text\"] + \" \"\n",
    "                page_content.append({\n",
    "                    \"type\": \"text\",\n",
    "                    \"content\": text.strip(),\n",
    "                    \"position\": block[\"bbox\"]\n",
    "                })\n",
    "            elif block[\"type\"] == 1:  # image block\n",
    "                xref = block[\"image\"]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                \n",
    "                # Создаем байтовый поток из извлеченных байтов изображения\n",
    "                image_stream = io.BytesIO(image_bytes)\n",
    "                \n",
    "                # Открываем изображение с помощью Pillow\n",
    "                pillow_image = Image.open(image_stream)\n",
    "                page_content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"content\": pillow_image,\n",
    "                    \"position\": block[\"bbox\"]\n",
    "                })\n",
    "        \n",
    "        content.extend(page_content)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_content_from_pdf(pdfFilePath):\n",
    "    doc = fitz.open(pdfFilePath)\n",
    "    content = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_content = []\n",
    "        \n",
    "        # Получаем все блоки на странице\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if block[\"type\"] == 0:  # block of text\n",
    "                for line in block[\"lines\"]:\n",
    "                    spans = []\n",
    "                    for span in line[\"spans\"]:\n",
    "                        spans.append(span[\"text\"])\n",
    "                    text = \" \".join(spans)\n",
    "                    page_content.append({\n",
    "                        \"type\": \"text\",\n",
    "                        \"content\": text.strip(),\n",
    "                        \"position\": block[\"bbox\"]\n",
    "                    })\n",
    "            elif block[\"type\"] == 1 and 'xref' in block:  # image block\n",
    "                xref = block['xref']\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                \n",
    "                # Создаем байтовый поток из извлеченных байтов изображения\n",
    "                image_stream = io.BytesIO(image_bytes)\n",
    "                \n",
    "                # Открываем изображение с помощью Pillow\n",
    "                pillow_image = Image.open(image_stream)\n",
    "                page_content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"content\": pillow_image,\n",
    "                    \"position\": block[\"bbox\"]\n",
    "                })\n",
    "        \n",
    "        content.extend(page_content)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_content_from_pdf(pdfFilePath):\n",
    "    doc = fitz.open(pdfFilePath)\n",
    "    content = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_content = []\n",
    "        \n",
    "        # Получаем все блоки на странице\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in blocks:\n",
    "            if block[\"type\"] == 0:  # block of text\n",
    "                for line in block[\"lines\"]:\n",
    "                    spans = []\n",
    "                    for span in line[\"spans\"]:\n",
    "                        spans.append(span[\"text\"])\n",
    "                    text = \" \".join(spans)\n",
    "                    page_content.append({\n",
    "                        \"type\": \"text\",\n",
    "                        \"content\": text.strip(),\n",
    "                        \"position\": block[\"bbox\"]\n",
    "                    })\n",
    "            elif block[\"type\"] == 1:  # image block\n",
    "                if 'image' in block and isinstance(block['image'], int):\n",
    "                    xref = block['image']\n",
    "                    base_image = doc.extract_image(xref)\n",
    "                    if base_image:  # Проверяем, что изображение успешно извлечено\n",
    "                        image_bytes = base_image[\"image\"]\n",
    "                        \n",
    "                        # Создаем байтовый поток из извлеченных байтов изображения\n",
    "                        image_stream = io.BytesIO(image_bytes)\n",
    "                        \n",
    "                        # Открываем изображение с помощью Pillow\n",
    "                        pillow_image = Image.open(image_stream)\n",
    "                        page_content.append({\n",
    "                            \"type\": \"image\",\n",
    "                            \"content\": pillow_image,\n",
    "                            \"position\": block[\"bbox\"]\n",
    "                        })\n",
    "        \n",
    "        # Сортируем содержимое страницы по верхней границе bounding box (bbox[1]),\n",
    "        # чтобы сохранить вертикальный порядок следования элементов.\n",
    "        page_content.sort(key=lambda item: item[\"position\"][1])\n",
    "        content.extend(page_content)\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "from src.backend.FileUtils import FileUtils\n",
    "from src.backend.OCR import tesseractOCR, easyOCR\n",
    "\n",
    "def extract_content_from_pdf(pdfFilePath):\n",
    "    doc = fitz.open(pdfFilePath)\n",
    "    content = []\n",
    "    ocr=easyOCR()\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        page_content = []\n",
    "\n",
    "        # Извлечение текста\n",
    "        text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        for block in text_blocks:\n",
    "            if block[\"type\"] == 0:  # block of text\n",
    "                text = \"\"\n",
    "                for line in block[\"lines\"]:\n",
    "                    for span in line[\"spans\"]:\n",
    "                        text += span[\"text\"] + \" \"\n",
    "                page_content.append({\n",
    "                    \"type\": \"text\",\n",
    "                    \"content\": text.strip(),\n",
    "                    \"position\": block[\"bbox\"]\n",
    "                })\n",
    "\n",
    "        # Извлечение изображений\n",
    "        image_blocks = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(image_blocks):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            pos=page.get_image_rects(img[0])\n",
    "            \n",
    "            if base_image:  # Убедимся, что изображение было извлечено\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_stream = io.BytesIO(image_bytes)\n",
    "                pillow_image = Image.open(image_stream)\n",
    "                page_content.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"content\": ocr.readText(pillow_image),\n",
    "                    \"position\": pos[0]  # img[1] содержит положение изображения на странице\n",
    "                })\n",
    "\n",
    "        # Сортировка содержимого страницы по вертикальной позиции на странице\n",
    "        page_content.sort(key=lambda item: (item[\"position\"][1]))\n",
    "        content.extend(page_content)\n",
    "    res = \"\"\n",
    "    for block in content:\n",
    "        res = res + block['content'] + ' '\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=extract_content_from_pdf(\"C:\\\\Users\\\\frima\\\\Downloads\\\\PDFAndPic.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=extract_content_from_pdf(\"C:\\\\Users\\\\frima\\\\Downloads\\\\PDFAndPic-2.pdf\")\n",
    "b=extract_content_from_pdf(\"C:\\\\Users\\\\frima\\\\Downloads\\\\PDFAndPic-1.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Глава 1. С добрым утром, братик Резкая боль в животе заставила Зориана распахнуть глаза. Он дёрнулся всем телом, прогибаясь под упавшим на него предметом, сон как рукой сняло. — С добрым утром, братик! — раздался над ним раздражающе-бодрый голос. — Доброго, доброго УТ-РЕ-ЧКА! Зориан сердито уставился на младшую сестру — но та лишь нахально улыбнулась, по-прежнему сидя у него на животе. Она удовлетворённо мурлыкала под нос и болтала ногами, разглядывая огромную карту мира, висящую над кроватью. Точнее, притворяясь, что разглядывает — Зориан видел, что она следит за ним краем глаза. Надо было сотворить вокруг кровати охранный периметр и запереть дверь магией. — Слезай, — как можно спокойнее сказал он. — Мама сказала разбудить тебя, — сообщила она, не двигаясь с места. — Не таким же образом, — проворчал он, сдерживая раздражение и терпеливо выжидая, когда она утратит бдительность. Так и есть, Кириэлле беспокойно завозилась уже после нескольких секунд деланного безразличия. И когда она уже не могла усидеть на месте — Зориан быстро ухватил её за ногу и за туловище и сбросил с кровати. Глухой удар, возмущённый вскрик — Зориан тут же вскочил на ноги, изготовившись на случай ответного нападения. Глянул сверху вниз и пренебрежительно фыркнул: — Я припомню это, когда меня попросят разбудить тебя. — Не судьба, — дерзко ответила она. — Ты всегда просыпаешься позже меня. Зориан лишь сокрушённо вздохнул. Мелкая чертовка была права. — Ну что... — возбуждённо начала она, вскочив на ноги. — Ты рад? Зориан смотрел, как она носится по комнате, словно обезьянка под кофеином. Иногда он завидовал её неуёмной энергии. Но только иногда. — Чему? — невинно спросил он, изображая непонимание. Само собой, он знал, о чём речь — но, спрашивая об очевидных вещах, можно было утомить сестру и прекратить нежеланный разговор. — Ты возвращаешься в академию, — пожаловалась она, видимо, разгадав его намерения. Нужно придумать парочку новых трюков. — Будешь учиться магии. Можешь показать немного магии? Зориан протяжно вздохнул. Кириэлле всегда относилась к нему, словно к приятелю-ровеснику, как бы он ни возражал — но раньше она держалась хоть каких-то рамок приличия. В этом году она была совершенно невыносима — а мать игнорировала его просьбы угомонить ребёнка. По её мнению, он всё равно не занимался ничем важным — только читал целыми днями. К счастью, летние каникулы заканчиваются — он может наконец убраться отсюда. — Кири, мне нужно собираться. Почему бы тебе не подоставать Фортова для разнообразия? Она состроила несчастную рожицу — потом просияла, словно вспомнив что-то, и стрелой выбежала из комнаты. Глаза Зориана расширились — он понял, в чём дело, но было уже поздно. — Нет! — заорал он, устремляясь вдогонку, но дверь захлопнулась прямо у него перед носом. В расстройстве он стукнул по ней кулаком. — Проклятье, Кири! Ты сто раз могла сходить в туалет, пока я спал! — Неудачник, — ответили из-за двери. Выругавшись, он развернулся и потопал назад в свою комнату, одеваться. Без сомнения, туалет занят надолго — назло ему. Быстро переодевшись и надев очки, Зориан оглядел комнату. Повезло — похоже, Кириэлле не рылась в его вещах, прежде чем разбудить. У неё очень смутное представление о чужой собственности. Сборы не заняли много времени — точнее, он и не разбирал вещи. Был бы хоть малейший шанс, что мать позволит, он вернулся бы в Сиорию ещё неделю назад. Проверяя учебные материалы, он с раздражением обнаружил пропажу нескольких учебников. Можно было попробовать заклинание поиска, но он и так догадывался, где их искать — Кириэлле частенько утаскивала их в свою  Глава 1. € добрым утром, братик Резкан боль аинате аастаннлн Зориана распахнуть глалн Он дернулся нсем телом  прогибаясь упавшим на него предметом сон как рукон анило УТСдобкым Доброго  доброго утром , братнк| рялдался шад ним ралдражающа-бодрый голог Зориан сердито устанипся на младшую сестру т5 лишлхалн Упыбнулась прежнему ло сндя унего на животе Она удовпатноренно мурлыпла подллос болтнла ногами рялгпядыная агромную карту мира нисящуюэ над кроватьн Точнне притдарялсь что рялглядиннет Зориан  видеп что она следит 5а ним краем глала Надо быпо сотворить вокруг кровати охранный перимстр внттароть цверь магиеи Слезан кяк можно споконнсе сказад он  Мама сказала ралбудить тебя соабщила онд не днигаясь мОсТа Не тяким же образом проварчал он сдерживая раздражение и терпеливо выжи Дая когда она Утратит одительность Так естъ Кириэлле беспокоино завозилась уже после нескольких секунд деланнога безразличня И когда она уже не могла усндеть на месте Зориан быстро ухнатил св за нагу за туловище сороснл кровати. Глухой удар возмущённыи вскрик Зориан тут же вскочнл на ноги изготовнвшись на случай ответн т нападсния- Глянул сверху вниз пренебрежительно фыркнул; Я припомню это когда попросят разбудить тебя ШЕ}л Не судъба дерзко ответнла она Ты всегда просыпаешься позже меня Зориан лишь сокрушённо ьздохнуп Мелкая чертовка была права Ну что возбуждённо начала она вскочив на наги Ты рад? Зориан смотрел как она носнтСя па комнате словно обезьянка под кофеином Иногда он завндовал ее неуемной энергин На только нногда Чему? невинно спрасип он нзабражая непониманис Сама собой ОН знал чем речь но: спрашивая 06 очевидных вещах можно было утомить сестру прекратить нежеланный разгавор Ты возвращаешься академию пожалоналась она виднмо пазгадав его намерешия Нужно придуматн парочку новых трюков Будешь читъся магин Можешь показать немного магни? Зориан протяжна здохнул Кириалле всегда относилась пему словно приятелю-ровеснику , как бы он ни возражал но раньше она держалась хоть каких то рамок приличня В этам году оня была совершенно евыносима мать игнорнровала его прасьбы угомонить ребенка По её мнению он все равно не заннмался ничем важным толыо чнтал целыми днямн счастъю летнне каникулы заканчиваются он может наконец убраться отстда Кири мне нужно собираться Почему бы тебе не подоставать Фортова для разнообразня? Она состроила несчастную рожицу патом проснялн славно вспомннь что-то стрелон ныбежала иа комнаты: Глазн Зорнана расширились о1 пОНяЛ чем тело на было уже поздно Нет! заорал андустремляясь вдагонку , но ддорь захлопнулась прямо нега перед носом; расгтронстве он стукнул по нен кулнком Проклятьв, Кирн! Ты сто раз могла сходить туалет пока СПАл Неудачник отватили 4з ча двери Выругавшись он раявернулся потопнл нилад камнату Баз сомнония; туалет внак доватьея занят надолго Наялогему; Быстро перцодавшись нндев очин, Зорннн оглядан комнату Попвяло похолч  Кирнанле на рыласы его нещах , првягда ралбудить неч очени ом}тнан нтрацатавлани; нужан а собственности Сборы не заняли много крамани тоинен ралбирал Шыщи Был хотъ Маланшни Шанс нто Матьпозаопнт он вернулся бы Снорпо оща тадата Пранерь чбныа миторналын он раздраж мем абнаружил пропажу нескопыких чооциков  Мажко дыдо попробонатъ чаклинанне панса но_#н т4к догадыва ЛС гда ИСкн74 Кириолдъ чНстоныко тас*ннила снит под '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"\"\n",
    "for i in a:\n",
    "    res = res +i['content'] + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Глава 1. С добрым утром, братик Резкая боль в животе заставила Зориана распахнуть глаза. Он дёрнулся всем телом, прогибаясь под упавшим на него предметом, сон как рукой сняло. — С добрым утром, братик! — раздался над ним раздражающе-бодрый голос. — Доброго, доброго УТ-РЕ-ЧКА! Зориан сердито уставился на младшую сестру — но та лишь нахально улыбнулась, по-прежнему сидя у него на животе. Она удовлетворённо мурлыкала под нос и болтала ногами, разглядывая огромную карту мира, висящую над кроватью. Точнее, притворяясь, что разглядывает — Зориан видел, что она следит за ним краем глаза. Надо было сотворить вокруг кровати охранный периметр и запереть дверь магией. — Слезай, — как можно спокойнее сказал он. — Мама сказала разбудить тебя, — сообщила она, не двигаясь с места. — Не таким же образом, — проворчал он, сдерживая раздражение и терпеливо выжидая, когда она утратит бдительность. Так и есть, Кириэлле беспокойно завозилась уже после нескольких секунд деланного безразличия. И когда она уже не могла усидеть на месте — Зориан быстро ухватил её за ногу и за туловище и сбросил с кровати. Глухой удар, возмущённый вскрик — Зориан тут же вскочил на ноги, изготовившись на случай ответного нападения. Глянул сверху вниз и пренебрежительно фыркнул: — Я припомню это, когда меня попросят разбудить тебя. — Не судьба, — дерзко ответила она. — Ты всегда просыпаешься позже меня. Зориан лишь сокрушённо вздохнул. Мелкая чертовка была права. — Ну что... — возбуждённо начала она, вскочив на ноги. — Ты рад? Зориан смотрел, как она носится по комнате, словно обезьянка под кофеином. Иногда он завидовал её неуёмной энергии. Но только иногда. — Чему? — невинно спросил он, изображая непонимание. Само собой, он знал, о чём речь — но, спрашивая об очевидных вещах, можно было утомить сестру и прекратить нежеланный разговор. — Ты возвращаешься в академию, — пожаловалась она, видимо, разгадав его намерения. Нужно придумать парочку новых трюков. — Будешь учиться магии. Можешь показать немного магии? Зориан протяжно вздохнул. Кириэлле всегда относилась к нему, словно к приятелю-ровеснику, как бы он ни возражал — но раньше она держалась хоть каких-то рамок приличия. В этом году она была совершенно невыносима — а мать игнорировала его просьбы угомонить ребёнка. По её мнению, он всё равно не занимался ничем важным — только читал целыми днями. К счастью, летние каникулы заканчиваются — он может наконец убраться отсюда. — Кири, мне нужно собираться. Почему бы тебе не подоставать Фортова для разнообразия? Она состроила несчастную рожицу — потом просияла, словно вспомнив что-то, и стрелой выбежала из комнаты. Глаза Зориана расширились — он понял, в чём дело, но было уже поздно. — Нет! — заорал он, устремляясь вдогонку, но дверь захлопнулась прямо у него перед носом. В расстройстве он стукнул по ней кулаком. — Проклятье, Кири! Ты сто раз могла сходить в туалет, пока я спал! — Неудачник, — ответили из-за двери. Выругавшись, он развернулся и потопал назад в свою комнату, одеваться. Без сомнения, туалет занят надолго — назло ему. Быстро переодевшись и надев очки, Зориан оглядел комнату. Повезло — похоже, Кириэлле не рылась в его вещах, прежде чем разбудить. У неё очень смутное представление о чужой собственности. Сборы не заняли много времени — точнее, он и не разбирал вещи. Был бы хоть малейший шанс, что мать позволит, он вернулся бы в Сиорию ещё неделю назад. Проверяя учебные материалы, он с раздражением обнаружил пропажу нескольких учебников. Можно было попробовать заклинание поиска, но он и так догадывался, где их искать — Кириэлле частенько утаскивала их в свою  Глава 1. € добрым утром, братик Резкан боль аинате аастаннлн Зориана распахнуть глалн Он дернулся нсем телом  прогибаясь упавшим на него предметом сон как рукон анило УТСдобкым Доброго  доброго утром , братнк| рялдался шад ним ралдражающа-бодрый голог Зориан сердито устанипся на младшую сестру т5 лишлхалн Упыбнулась прежнему ло сндя унего на животе Она удовпатноренно мурлыпла подллос болтнла ногами рялгпядыная агромную карту мира нисящуюэ над кроватьн Точнне притдарялсь что рялглядиннет Зориан  видеп что она следит 5а ним краем глала Надо быпо сотворить вокруг кровати охранный перимстр внттароть цверь магиеи Слезан кяк можно споконнсе сказад он  Мама сказала ралбудить тебя соабщила онд не днигаясь мОсТа Не тяким же образом проварчал он сдерживая раздражение и терпеливо выжи Дая когда она Утратит одительность Так естъ Кириэлле беспокоино завозилась уже после нескольких секунд деланнога безразличня И когда она уже не могла усндеть на месте Зориан быстро ухнатил св за нагу за туловище сороснл кровати. Глухой удар возмущённыи вскрик Зориан тут же вскочнл на ноги изготовнвшись на случай ответн т нападсния- Глянул сверху вниз пренебрежительно фыркнул; Я припомню это когда попросят разбудить тебя ШЕ}л Не судъба дерзко ответнла она Ты всегда просыпаешься позже меня Зориан лишь сокрушённо ьздохнуп Мелкая чертовка была права Ну что возбуждённо начала она вскочив на наги Ты рад? Зориан смотрел как она носнтСя па комнате словно обезьянка под кофеином Иногда он завндовал ее неуемной энергин На только нногда Чему? невинно спрасип он нзабражая непониманис Сама собой ОН знал чем речь но: спрашивая 06 очевидных вещах можно было утомить сестру прекратить нежеланный разгавор Ты возвращаешься академию пожалоналась она виднмо пазгадав его намерешия Нужно придуматн парочку новых трюков Будешь читъся магин Можешь показать немного магни? Зориан протяжна здохнул Кириалле всегда относилась пему словно приятелю-ровеснику , как бы он ни возражал но раньше она держалась хоть каких то рамок приличня В этам году оня была совершенно евыносима мать игнорнровала его прасьбы угомонить ребенка По её мнению он все равно не заннмался ничем важным толыо чнтал целыми днямн счастъю летнне каникулы заканчиваются он может наконец убраться отстда Кири мне нужно собираться Почему бы тебе не подоставать Фортова для разнообразня? Она состроила несчастную рожицу патом проснялн славно вспомннь что-то стрелон ныбежала иа комнаты: Глазн Зорнана расширились о1 пОНяЛ чем тело на было уже поздно Нет! заорал андустремляясь вдагонку , но ддорь захлопнулась прямо нега перед носом; расгтронстве он стукнул по нен кулнком Проклятьв, Кирн! Ты сто раз могла сходить туалет пока СПАл Неудачник отватили 4з ча двери Выругавшись он раявернулся потопнл нилад камнату Баз сомнония; туалет внак доватьея занят надолго Наялогему; Быстро перцодавшись нндев очин, Зорннн оглядан комнату Попвяло похолч  Кирнанле на рыласы его нещах , првягда ралбудить неч очени ом}тнан нтрацатавлани; нужан а собственности Сборы не заняли много крамани тоинен ралбирал Шыщи Был хотъ Маланшни Шанс нто Матьпозаопнт он вернулся бы Снорпо оща тадата Пранерь чбныа миторналын он раздраж мем абнаружил пропажу нескопыких чооциков  Мажко дыдо попробонатъ чаклинанне панса но_#н т4к догадыва ЛС гда ИСкн74 Кириолдъ чНстоныко тас*ннила снит под '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text',\n",
       "  'content': 'шься в академию, — пожаловалась она, видимо, разгадав его намерения. Нужно придумать парочку новых трюков. — Будешь учиться магии. Можешь показать немного магии? Зориан протяжно вздохнул. Кириэлле всегда относилась к нему, словно к приятелю-ровеснику, как бы он ни возражал — но раньше она держалась хоть каких-то рамок приличия. В этом году она была совершенно невыносима — а мать игнорировала его просьбы угомонить ребёнка. По её мнению, он всё равно не занимался ничем важным — только читал целыми днями. К счастью, летние каникулы заканчиваются — он может наконец убраться отсюда. — Кири, мне нужно собираться. Почему бы тебе не подоставать Фортова для разнообразия? Она состроила несчастную рожицу — потом просияла, словно вспомнив что-то, и стрелой выбежала из комнаты. Глаза Зориана расширились — он понял, в чём дело, но было уже поздно. — Нет! — заорал он, устремляясь вдогонку, но дверь захлопнулась прямо у него перед носом. В расстройстве он стукнул по ней кулаком. — Проклятье, Кири! Ты сто раз могла сходить в туалет, пока я спал! — Неудачник, — ответили из-за двери. Выругавшись, он развернулся и потопал назад в свою комнату, одеваться. Без сомнения, туалет занят надолго — назло ему. Быстро переодевшись и надев очки, Зориан оглядел комнату. Повезло — похоже, Кириэлле не рылась в его вещах, прежде чем разбудить. У неё очень смутное представление о чужой собственности. Сборы не заняли много времени — точнее, он и не разбирал вещи. Был бы хоть малейший шанс, что мать позволит, он вернулся бы в Сиорию ещё неделю назад. Проверяя учебные материалы, он с раздражением обнаружил пропажу нескольких учебников. Можно было попробовать заклинание поиска, но он и так догадывался, где их искать — Кириэлле частенько утаскивала их в свою',\n",
       "  'position': (0,\n",
       "   (72.0, 72.35986328125, 522.2998657226562, 404.666748046875))},\n",
       " {'type': 'image',\n",
       "  'content': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=960x1280>,\n",
       "  'position': (0, [Rect(73.5, 408.0640869140625, 340.5, 764.3140869140625)])}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = []\n",
    "for i,block in enumerate(a):\n",
    "    if(block['type'] not in types):\n",
    "        types.append(block['type'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'image']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "class BertAnalyse:\n",
    "\n",
    "    def __init__(self):\n",
    "        #штука для превращения слов в токены\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
    "        self.model = BertModel.from_pretrained('sberbank-ai/ruBert-base')\n",
    "    def get_embedding(self, text, device='cpu'):\n",
    "        # Токенизируем текст\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "\n",
    "        # Разделяем токенизированный текст на части по 512 токенов\n",
    "        max_chunk_size = 512 - 2  # уменьшаем на 2, чтобы вместить специальные токены [CLS] и [SEP]\n",
    "        chunks = [tokenized_text[i:i + max_chunk_size] for i in range(0, len(tokenized_text), max_chunk_size)]\n",
    "\n",
    "        # Инициализируем пустой список для эмбеддингов\n",
    "        chunk_embeddings = []\n",
    "\n",
    "        for chunk in chunks:\n",
    "            # Добавляем специальные токены в начало и конец части\n",
    "            chunk = ['[CLS]'] + chunk + ['[SEP]']\n",
    "            # Конвертируем список токенов в тензоры\n",
    "            inputs = self.tokenizer.encode_plus(chunk, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # Получаем выходные данные модели\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "\n",
    "            # Берем эмбеддинги от последнего слоя модели BERT\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "            # Берем эмбеддинг для [CLS] токена\n",
    "            chunk_embedding = last_hidden_states[:, 0, :].squeeze()\n",
    "            chunk_embeddings.append(chunk_embedding)\n",
    "\n",
    "        # Объединяем эмбеддинги всех частей\n",
    "        embeddings = torch.mean(torch.stack(chunk_embeddings), dim=0)\n",
    "        return embeddings\n",
    "    def compare_text(self,text1, text2):\n",
    "        emb1 = self.get_embedding(text1)\n",
    "        emb2 = self.get_embedding(text2)\n",
    "        return 1 - cosine(emb1, emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "class BertAnalyse:\n",
    "\n",
    "    def __init__(self):\n",
    "        #штука для превращения слов в токены\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
    "        self.model = BertModel.from_pretrained('sberbank-ai/ruBert-base')\n",
    "    def get_embedding(self, text1,text2, device='cpu'):\n",
    "        # Токенизируем текст\n",
    "        tokenized_text1 = self.tokenizer.tokenize(text1)\n",
    "        tokenized_text2 = self.tokenizer.tokenize(text2)\n",
    "\n",
    "        # Разделяем токенизированный текст на части по 512 токенов\n",
    "        max_chunk_size = 512 - 2  # уменьшаем на 2, чтобы вместить специальные токены [CLS] и [SEP]\n",
    "        chunks_text1 = [tokenized_text1[i:i + max_chunk_size] for i in range(0, len(tokenized_text1), max_chunk_size)]\n",
    "        chunks_text2 = [tokenized_text2[i:i + max_chunk_size] for i in range(0, len(tokenized_text2), max_chunk_size)]\n",
    "\n",
    "        # Инициализируем пустой список для эмбеддингов\n",
    "        chunk_compare = []\n",
    "\n",
    "        for chunk1,chunk2 in zip(chunks_text1,chunks_text2):\n",
    "            # Добавляем специальные токены в начало и конец части\n",
    "            chunk1 = ['[CLS]'] + chunk1 + ['[SEP]']\n",
    "            chunk2 = ['[CLS]'] + chunk2 + ['[SEP]']\n",
    "            # Конвертируем список токенов в тензоры\n",
    "            inputs1 = self.tokenizer.encode_plus(chunk1, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs1 = inputs1.to(device)\n",
    "            inputs2 = self.tokenizer.encode_plus(chunk2, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs2 = inputs2.to(device)\n",
    "\n",
    "            # Получаем выходные данные модели\n",
    "            with torch.no_grad():\n",
    "                outputs1 = self.model(**inputs1)\n",
    "                outputs2 = self.model(**inputs2)\n",
    "\n",
    "            # Берем эмбеддинги от последнего слоя модели BERT\n",
    "            last_hidden_states1 = outputs1.last_hidden_state\n",
    "            last_hidden_states2 = outputs2.last_hidden_state\n",
    "            # Берем эмбеддинг для [CLS] токена\n",
    "            chunk_embedding1 = torch.mean(last_hidden_states1, dim=1).squeeze()\n",
    "            chunk_embedding2 = torch.mean(last_hidden_states2, dim=1).squeeze()\n",
    "            chunk_compare.append(1 - cosine(chunk_embedding1, chunk_embedding2))\n",
    "        mean_similarity=sum(chunk_compare)/len(chunk_compare)\n",
    "\n",
    "        return mean_similarity\n",
    "    def compare_text(self,text1, text2):\n",
    "        return self.get_embedding(text1,text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"hello\"\n",
    "b = \"hye\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871604323387146"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertAnalyse().compare_text(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompare_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 37\u001b[0m, in \u001b[0;36mcompare_text\u001b[1;34m(text1, text2)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_text\u001b[39m(text1, text2):\n\u001b[1;32m---> 37\u001b[0m     emb1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     emb2 \u001b[38;5;241m=\u001b[39m get_embedding(text2)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m cosine(emb1, emb2)\n",
      "Cell \u001b[1;32mIn[20], line 7\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text, device)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embedding\u001b[39m(text, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Токенизируем текст\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     tokenized_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Разделяем токенизированный текст на части по 512 токенов\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     max_chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# уменьшаем на 2, чтобы вместить специальные токены [CLS] и [SEP]\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "compare_text(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "class BertAnalyse:\n",
    "\n",
    "    def __init__(self):\n",
    "        #штука для превращения слов в токены\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('sberbank-ai/ruBert-base')\n",
    "        self.model = BertModel.from_pretrained('sberbank-ai/ruBert-base')\n",
    "    def get_mean_similarity(self, text1,text2, device='cpu'):\n",
    "        # Токенизируем текст\n",
    "        tokenized_text1 = self.tokenizer.tokenize(text1)\n",
    "        tokenized_text2 = self.tokenizer.tokenize(text2)\n",
    "\n",
    "        # Разделяем токенизированный текст на части по 512 токенов\n",
    "        max_chunk_size = 512 - 2  # уменьшаем на 2, чтобы вместить специальные токены [CLS] и [SEP]\n",
    "        chunks_text1 = [tokenized_text1[i:i + max_chunk_size] for i in range(0, len(tokenized_text1), max_chunk_size)]\n",
    "        chunks_text2 = [tokenized_text2[i:i + max_chunk_size] for i in range(0, len(tokenized_text2), max_chunk_size)]\n",
    "\n",
    "        # Инициализируем пустой список для эмбеддингов\n",
    "        chunk_compare = []\n",
    "\n",
    "        for chunk1,chunk2 in zip(chunks_text1,chunks_text2):\n",
    "            # Добавляем специальные токены в начало и конец части\n",
    "            chunk1 = ['[CLS]'] + chunk1 + ['[SEP]']\n",
    "            chunk2 = ['[CLS]'] + chunk2 + ['[SEP]']\n",
    "            # Конвертируем список токенов в тензоры\n",
    "            inputs1 = self.tokenizer.encode_plus(chunk1, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs1 = inputs1.to(device)\n",
    "            inputs2 = self.tokenizer.encode_plus(chunk2, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs2 = inputs2.to(device)\n",
    "\n",
    "            # Получаем выходные данные модели\n",
    "            with torch.no_grad():\n",
    "                outputs1 = self.model(**inputs1)\n",
    "                outputs2 = self.model(**inputs2)\n",
    "\n",
    "            # Берем эмбеддинги от последнего слоя модели BERT\n",
    "            last_hidden_states1 = outputs1.last_hidden_state\n",
    "            last_hidden_states2 = outputs2.last_hidden_state\n",
    "            # Берем эмбеддинг для [CLS] токена\n",
    "            chunk_embedding1 = torch.mean(last_hidden_states1, dim=1).squeeze()\n",
    "            chunk_embedding2 = torch.mean(last_hidden_states2, dim=1).squeeze()\n",
    "            chunk_compare.append(1 - cosine(chunk_embedding1, chunk_embedding2))\n",
    "        if chunk_compare:\n",
    "            mean_similarity = sum(chunk_compare) / len(chunk_compare)\n",
    "        else:\n",
    "            mean_similarity = 0\n",
    "\n",
    "        return mean_similarity\n",
    "    def compare_text(self,text1, text2):\n",
    "        return self.get_mean_similarity(text1,text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"5.346\"\n",
    "b = \"Привет\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6584801077842712"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertAnalyse().compare_text(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
